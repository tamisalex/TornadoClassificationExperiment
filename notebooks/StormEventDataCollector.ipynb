{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn as sk \n",
    "import sqlalchemy\n",
    "import seaborn as sns\n",
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import zipfile\n",
    "from StringIO import StringIO\n",
    "import gzip\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetFile(filename):\n",
    "    baseURL = \"http://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/\"\n",
    "\n",
    "    response = urllib2.urlopen(baseURL + filename)\n",
    "    compressedFile = StringIO()\n",
    "    compressedFile.write(response.read())\n",
    "    #\n",
    "    # Set the file's current position to the beginning\n",
    "    # of the file so that gzip.GzipFile can read\n",
    "    # its contents from the top.\n",
    "    #\n",
    "    compressedFile.seek(0)\n",
    "\n",
    "    decompressedFile = gzip.GzipFile(fileobj=compressedFile, mode='rb')\n",
    "\n",
    "    return decompressedFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GetFileList():\n",
    "    weatherDataUrl = \"http://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/\"\n",
    "    soup = BeautifulSoup(requests.get(weatherDataUrl).text, \"lxml\")\n",
    "    fileList = []\n",
    "    for a in soup.find_all('a'):\n",
    "            if \"StormEvents\" in a[\"href\"]:\n",
    "                fileList.append(a[\"href\"])\n",
    "    return fileList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetFile_Convert_Append(filename,df):\n",
    "    csvFile = GetFile(filename)\n",
    "    csv = pd.read_csv(csvFile)\n",
    "    csv.columns = map(str.lower,csv.columns)\n",
    "    #csv.to_sql(\"details\",con = engine, if_exists = \"replace\", chunksize=500)\n",
    "    df = df.append(csv)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Collect():\n",
    "    engine = sqlalchemy.create_engine('postgresql://alexandertam@localhost/')\n",
    "    \n",
    "    fileTypes = [\"details\",\"locations\",\"fatalities\"]\n",
    "    years = range(2015,2016)\n",
    "    years = map(str,years)\n",
    "    detailsDF = pd.DataFrame()\n",
    "    locationsDF = pd.DataFrame()\n",
    "    fatalitiesDF = pd.DataFrame()\n",
    "    \n",
    "    for filename in GetFileList():\n",
    "        if any(year in filename for year in years):\n",
    "            if(\"details\" in filename):\n",
    "                detailsDF = GetFile_Convert_Append(filename,detailsDF)\n",
    "                continue\n",
    "            if(\"fatalities\" in filename):\n",
    "                fatalitiesDF = GetFile_Convert_Append(filename,fatalitiesDF)\n",
    "                continue\n",
    "            if(\"locations\" in filename):\n",
    "                locationsDF = GetFile_Convert_Append(filename,locationsDF)\n",
    "                continue\n",
    "            \n",
    "    TornadoesDF = detailsDF[detailsDF[\"event_type\"]==\"Tornado\"]\n",
    "    \n",
    "    fatalitiesDF.to_sql(\"fatalities\",con = engine, if_exists = \"replace\")\n",
    "    \n",
    "    AlabamaDF = detailsDF[detailsDF[\"state\"] ==  \"ALABAMA\"].copy()\n",
    "    AlabamaDF = AlabamaDF[AlabamaDF[\"wfo\"] != \"TAE\"]\n",
    "    AlabamaDF = AlabamaDF[[\"wfo\",\"episode_id\",\"event_id\",\"event_type\",\"begin_date_time\",\"end_date_time\",\"begin_lat\",\"begin_lon\"]]\n",
    "    AlabamaDF = AlabamaDF.dropna()\n",
    "    AlabamaDF.to_sql(\"alabama\",con = engine, if_exists = \"replace\")\n",
    "    locationsDF.to_sql(\"locations\",con = engine, if_exists = \"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
