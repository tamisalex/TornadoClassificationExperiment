{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor,AdaBoostRegressor, RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine('postgresql://alexandertam@localhost/postgres')\n",
    "data = pd.read_sql('SELECT * FROM data',con = engine)\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    del data[\"index\"]\n",
    "except:\n",
    "    pass\n",
    "y = data.iloc[:,1]\n",
    "X = data.iloc[:,7:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score:  0.943609022556\n"
     ]
    }
   ],
   "source": [
    "logiReg = LogisticRegression()\n",
    "model = logiReg.fit(X,y)\n",
    "predictions = model.predict(X)\n",
    "print \"Model score: \", model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.943609022556\n",
      "Precision score:  0.0\n",
      "Recall score:  0.0\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy score: \", accuracy_score(y,predictions)\n",
    "print \"Precision score: \", precision_score(y,predictions)\n",
    "print \"Recall score: \", recall_score(y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsTornado</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0        0\n",
       "IsTornado     \n",
       "0          502\n",
       "1           30"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def PredictProbaLogisticRegression(X_test,y_test,model):\n",
    "    #print \"Model score: \", model.score(X_test,y_test)\n",
    "    return model.predict_proba(X_test)\n",
    "\n",
    "proba_predictions = PredictProbaLogisticRegression(X,y,model)\n",
    "#print proba_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score:  0.796992481203\n",
      "Accuracy score:  0.812030075188\n",
      "Precision score:  0.175925925926\n",
      "Recall score:  0.633333333333\n",
      "Critical Success Index:  0.121951219512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predictions</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>408</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predictions  0.0  1.0\n",
       "Actual               \n",
       "0.0          408   93\n",
       "1.0           15   15"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Classifier(probability,threshold):\n",
    "    if(probability > threshold):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def ClassifyProbabilities(probabilities,threshold):\n",
    "    classifieds = []\n",
    "    for probability in probabilities:\n",
    "        classifieds.append(Classifier(probability, threshold))\n",
    "    return classifieds\n",
    "\n",
    "def CriticalSuccessIndex(hits, misses, falseAlarms):\n",
    "    return hits/float(hits + misses + falseAlarms)\n",
    "\n",
    "def ActualToPredictedConfusionMatrix(y, predictions):\n",
    "    actuals = pd.Series(y,name=\"Actual\")\n",
    "    predicted = pd.Series(predictions,name = \"Predictions\")\n",
    "    return pd.crosstab(actuals,predicted)\n",
    "    \n",
    "newClassifieds = ClassifyProbabilities(pd.DataFrame(proba_predictions)[1],.1)\n",
    "#print newClassifieds\n",
    "\n",
    "ActualToPredictedConfusionMatrix(y,newClassifieds)\n",
    "print \"Model score: \", model.score(X,newClassifieds)\n",
    "print \"Accuracy score: \", accuracy_score(y,newClassifieds)\n",
    "print \"Precision score: \", precision_score(y,newClassifieds)\n",
    "print \"Recall score: \", recall_score(y,newClassifieds)\n",
    "\n",
    "cm = ActualToPredictedConfusionMatrix(y,newClassifieds)\n",
    "hits = cm[1][1]\n",
    "falseAlarms = cm[1][0]\n",
    "misses = cm[0][1]\n",
    "\n",
    "print \"Critical Success Index: \", CriticalSuccessIndex(hits,misses,falseAlarms)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score:  0.943609022556\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=7)\n",
    "model.fit(X,y)\n",
    "predictions = model.predict(X)\n",
    "print \"Model score: \", model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.943609022556\n",
      "Precision score:  0.0\n",
      "Recall score:  0.0\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy score: \", accuracy_score(y,predictions)\n",
    "print \"Precision score: \", precision_score(y,predictions)\n",
    "print \"Recall score: \", recall_score(y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
