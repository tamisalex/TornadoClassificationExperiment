{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn as sk \n",
    "import sqlalchemy\n",
    "import seaborn as sns\n",
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import zipfile\n",
    "from StringIO import StringIO\n",
    "import gzip\n",
    "import datetime\n",
    "import pytz\n",
    "import os\n",
    "\n",
    "import boto\n",
    "import boto3\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine('postgresql://alexandertam@localhost/postgres')\n",
    "\n",
    "#engine = sqlalchemy.create_engine(\"postgresql://overlord:Tamtyacm205Overlord@darkmatter.cyrl8cvgtnrm.us-west-2.rds.amazonaws.com:5432/darkmatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>begin_yearmonth</th>\n",
       "      <th>begin_day</th>\n",
       "      <th>begin_time</th>\n",
       "      <th>end_yearmonth</th>\n",
       "      <th>end_day</th>\n",
       "      <th>end_time</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>event_id</th>\n",
       "      <th>state</th>\n",
       "      <th>...</th>\n",
       "      <th>end_range</th>\n",
       "      <th>end_azimuth</th>\n",
       "      <th>end_location</th>\n",
       "      <th>begin_lat</th>\n",
       "      <th>begin_lon</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lon</th>\n",
       "      <th>episode_narrative</th>\n",
       "      <th>event_narrative</th>\n",
       "      <th>data_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>292</td>\n",
       "      <td>201501</td>\n",
       "      <td>7</td>\n",
       "      <td>2000</td>\n",
       "      <td>201501</td>\n",
       "      <td>8</td>\n",
       "      <td>600</td>\n",
       "      <td>91370</td>\n",
       "      <td>547659</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>An Arctic cold front pushed through the region...</td>\n",
       "      <td>Wind chills fell below zero around 8 pm on the...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>293</td>\n",
       "      <td>201501</td>\n",
       "      <td>7</td>\n",
       "      <td>2000</td>\n",
       "      <td>201501</td>\n",
       "      <td>8</td>\n",
       "      <td>600</td>\n",
       "      <td>91370</td>\n",
       "      <td>547660</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>An Arctic cold front pushed through the region...</td>\n",
       "      <td>Wind chills fell below zero around 8 pm on the...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>294</td>\n",
       "      <td>201501</td>\n",
       "      <td>7</td>\n",
       "      <td>2000</td>\n",
       "      <td>201501</td>\n",
       "      <td>8</td>\n",
       "      <td>700</td>\n",
       "      <td>91370</td>\n",
       "      <td>547662</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>An Arctic cold front pushed through the region...</td>\n",
       "      <td>Wind chills fell below zero around 8 pm on the...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>545</td>\n",
       "      <td>201501</td>\n",
       "      <td>15</td>\n",
       "      <td>700</td>\n",
       "      <td>201501</td>\n",
       "      <td>15</td>\n",
       "      <td>1200</td>\n",
       "      <td>91612</td>\n",
       "      <td>558164</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A weather system sweeping through the deep Sou...</td>\n",
       "      <td>A mixture of light snow and sleet resulted in ...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>787</td>\n",
       "      <td>201501</td>\n",
       "      <td>15</td>\n",
       "      <td>730</td>\n",
       "      <td>201501</td>\n",
       "      <td>15</td>\n",
       "      <td>1230</td>\n",
       "      <td>91612</td>\n",
       "      <td>556032</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A weather system sweeping through the deep Sou...</td>\n",
       "      <td>A mixture of light snow and sleet resulted in ...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  begin_yearmonth  begin_day  begin_time  end_yearmonth  end_day  \\\n",
       "0    292           201501          7        2000         201501        8   \n",
       "1    293           201501          7        2000         201501        8   \n",
       "2    294           201501          7        2000         201501        8   \n",
       "3    545           201501         15         700         201501       15   \n",
       "4    787           201501         15         730         201501       15   \n",
       "\n",
       "   end_time  episode_id  event_id    state     ...      end_range  \\\n",
       "0       600       91370    547659  ALABAMA     ...            NaN   \n",
       "1       600       91370    547660  ALABAMA     ...            NaN   \n",
       "2       700       91370    547662  ALABAMA     ...            NaN   \n",
       "3      1200       91612    558164  ALABAMA     ...            NaN   \n",
       "4      1230       91612    556032  ALABAMA     ...            NaN   \n",
       "\n",
       "   end_azimuth end_location begin_lat begin_lon  end_lat end_lon  \\\n",
       "0         None         None       NaN       NaN      NaN     NaN   \n",
       "1         None         None       NaN       NaN      NaN     NaN   \n",
       "2         None         None       NaN       NaN      NaN     NaN   \n",
       "3         None         None       NaN       NaN      NaN     NaN   \n",
       "4         None         None       NaN       NaN      NaN     NaN   \n",
       "\n",
       "                                   episode_narrative  \\\n",
       "0  An Arctic cold front pushed through the region...   \n",
       "1  An Arctic cold front pushed through the region...   \n",
       "2  An Arctic cold front pushed through the region...   \n",
       "3  A weather system sweeping through the deep Sou...   \n",
       "4  A weather system sweeping through the deep Sou...   \n",
       "\n",
       "                                     event_narrative data_source  \n",
       "0  Wind chills fell below zero around 8 pm on the...         CSV  \n",
       "1  Wind chills fell below zero around 8 pm on the...         CSV  \n",
       "2  Wind chills fell below zero around 8 pm on the...         CSV  \n",
       "3  A mixture of light snow and sleet resulted in ...         CSV  \n",
       "4  A mixture of light snow and sleet resulted in ...         CSV  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AlabamaDF = pd.read_sql('SELECT * FROM alabama',con = engine)\n",
    "#AlabamaDF.head()\n",
    "weather = AlabamaDF\n",
    "weather.head()\n",
    "#tornadoes = AlabamaDF[AlabamaDF[\"event_type\"] == \"Tornado\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'index', u'begin_yearmonth', u'begin_day', u'begin_time',\n",
       "       u'end_yearmonth', u'end_day', u'end_time', u'episode_id', u'event_id',\n",
       "       u'state', u'state_fips', u'year', u'month_name', u'event_type',\n",
       "       u'cz_type', u'cz_fips', u'cz_name', u'wfo', u'begin_date_time',\n",
       "       u'cz_timezone', u'end_date_time', u'injuries_direct',\n",
       "       u'injuries_indirect', u'deaths_direct', u'deaths_indirect',\n",
       "       u'damage_property', u'damage_crops', u'source', u'magnitude',\n",
       "       u'magnitude_type', u'flood_cause', u'category', u'tor_f_scale',\n",
       "       u'tor_length', u'tor_width', u'tor_other_wfo', u'tor_other_cz_state',\n",
       "       u'tor_other_cz_fips', u'tor_other_cz_name', u'begin_range',\n",
       "       u'begin_azimuth', u'begin_location', u'end_range', u'end_azimuth',\n",
       "       u'end_location', u'begin_lat', u'begin_lon', u'end_lat', u'end_lon',\n",
       "       u'episode_narrative', u'event_narrative', u'data_source'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTimeParts(utc):\n",
    "    year = str(utc.year)\n",
    "    month = str(utc.month)\n",
    "    if len(month) == 1:\n",
    "        month = \"0\" + month\n",
    "    day = str(utc.day)\n",
    "    if len(day) == 1:\n",
    "        day = \"0\" + day\n",
    "    hour = str(utc.hour)\n",
    "    if len(hour) == 1:\n",
    "        hour = \"0\" + hour\n",
    "    minutes = str(utc.minute)\n",
    "    if len(minutes) == 1:\n",
    "        minutes = \"0\" + minutes\n",
    "    seconds = str(utc.second)\n",
    "    if len(seconds) == 1:\n",
    "        seconds = \"0\" + seconds\n",
    "    return (year,month,day,hour,minutes,seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def buildPath(station,utc):\n",
    "    year, month, day, hours, minutes, seconds = getTimeParts(utc)\n",
    "    path = year+\"/\"+month+\"/\"+day+\"/K\"+station+\"/\"\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTimePortion(filename):\n",
    "    time = filename.split(\"_\")[1]\n",
    "    d = datetime.datetime.strptime(time, '%H%M%S')\n",
    "    return d.strftime('%H:%M:%S')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTimeDifferences(tornadoTime,ListOfTimes):\n",
    "    ttime = datetime.datetime.strptime(tornadoTime, '%H:%M:%S')\n",
    "    timeDifferences = []\n",
    "    minimum \n",
    "    minimumTime\n",
    "    for time in ListOfTimes:\n",
    "        ftime = datetime.datetime.strptime(time, '%H:%M:%S')\n",
    "        minTime = ttime - ftime\n",
    "        timeDifferences.append((ftime,minTime))\n",
    "    return timeDifferences       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSelectedTimes(station,utc):\n",
    "    # read a volume scan file on S3. Get Files for Date and Station\n",
    "    s3conn = boto.connect_s3()\n",
    "    bucket = s3conn.get_bucket('noaa-nexrad-level2')\n",
    "\n",
    "    selectedFilenames = [key.name for key in bucket.list(buildPath(station,utc)) if \".gz\" in key.name]     \n",
    "    selectedTimes = map(getTimePortion,selectedFilenames)\n",
    "    return selectedTimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def closestTime(tornadoTime,radarTimeList):\n",
    "    timeTuples = []\n",
    "    b_d = datetime.datetime.strptime(tornadoTime, \"%H:%M:%S\")\n",
    "    for radarTime in radarTimeList:\n",
    "        d =  datetime.datetime.strptime(radarTime, \"%H:%M:%S\")\n",
    "        delta = b_d - d if b_d > d else datetime.timedelta.max\n",
    "        timeTuples.append((delta,d))\n",
    "    triangle, actual = min(timeTuples, key = lambda t: t[0])\n",
    "    if(actual != None):\n",
    "        #print actual.strftime(\"%H%M%S\")\n",
    "        return (actual.strftime(\"%H%M%S\"),actual.strftime(\"%H:%M:%S\"))\n",
    "    #else:\n",
    "        #return \"hey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildFileID(station,utc,closestTimeStamp):\n",
    "    year, month, day, hour, minutes, seconds = getTimeParts(utc)\n",
    "    fileID = \"K\" + station + year + month +  day + \"_\" + closestTimeStamp\n",
    "    if(int(year) >= 2012):\n",
    "        fileID += \"_V06.gz\"\n",
    "    else:\n",
    "        fileID += \"_V03.gz\"\n",
    "    return fileID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildKey(station,utc,closestTimeStamp):\n",
    "    path = buildPath(station,utc)\n",
    "    fileID = buildFileID(station,utc,closestTimeStamp)\n",
    "    key = path + fileID\n",
    "    return key\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def UpdateStationCode(station):\n",
    "    if(station == \"HUN\"):\n",
    "        return \"HTX\"\n",
    "    return station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GetFileFromNexradAWS(key):\n",
    "    fileID = buildFileID(station,utc,closestTimeStamp)\n",
    "    print \"Downloading: \", fileID\n",
    "    try:\n",
    "        s3conn = boto.connect_s3()\n",
    "        bucket = s3conn.get_bucket('noaa-nexrad-level2')\n",
    "        s3key = bucket.get_key(key)\n",
    "        s3key.get_contents_to_filename(\"../assets/\"+fileID)\n",
    "    except:\n",
    "        \"An error occured trying to download the file \", key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GetBucketSize():\n",
    "    s3conn = boto.connect_s3()\n",
    "    bucket = s3conn.get_bucket('noaa-nexrad-level2')\n",
    "    size = 0\n",
    "    for key in bucket.list():\n",
    "        size += key.size\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = []\n",
    "TornadoTime = []\n",
    "VolumeTime = []\n",
    "OriginalTime = []\n",
    "IsTornado = []\n",
    "episode_ids = []\n",
    "event_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading:  KHTX20150108_015156_V06.gz\n",
      "Event   :  0.14\n"
     ]
    }
   ],
   "source": [
    "for i in range((len(weather))-1):\n",
    "    event = weather.iloc[i,:]\n",
    "    central = pytz.timezone('US/Central')\n",
    "    d = datetime.datetime.strptime(event.begin_date_time, '%d-%b-%y %H:%M:%S')\n",
    "    local = central.localize(d)\n",
    "    utc = local.astimezone(pytz.utc)\n",
    "    station = event.wfo\n",
    "    station = UpdateStationCode(station)\n",
    "    selectedTimes = getSelectedTimes(station,utc)\n",
    "    tornadoTime = utc.strftime('%H:%M:%S')\n",
    "    if (selectedTimes !=  []):\n",
    "        closestTimeStamp, formatted = closestTime(tornadoTime,selectedTimes)\n",
    "        key = buildKey(station,utc,closestTimeStamp)\n",
    "        filename = buildFileID(station,utc,closestTimeStamp)\n",
    "        if(not os.path.isfile(filename)):\n",
    "            GetFileFromNexradAWS(key)\n",
    "            VolumeTime.append(formatted)\n",
    "            TornadoTime.append(tornadoTime)\n",
    "            filenames.append(filename)\n",
    "            OriginalTime.append(d.strftime('%H:%M:%S'))\n",
    "            episode_ids.append(event.episode_id)\n",
    "            event_ids.append(event.event_id)\n",
    "            #BeginLat.append(event.begin_lat)\n",
    "            #BeginLong.append(event.begin_lon)\n",
    "            if event.event_type == \"Tornado\":\n",
    "                IsTornado.append(1)\n",
    "                print \"Tornado : \", round(float(i+1)/(len(weather)-1) * 100,2)\n",
    "            else:\n",
    "                IsTornado.append(0)\n",
    "                print \"Event   : \", round(float(i+1)/(len(weather)-1) * 100,2)\n",
    "            \n",
    "    else:\n",
    "        print \"Event   : \",round(float(i)/len(weather) * 100,2)\n",
    "        print \"Could not find keys for: \", station, tornadoTime\n",
    "    \n",
    "    if i == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i in range((len(weather))-1):\n",
    "# #for i in range(100):\n",
    "#     event = weather.iloc[i,:]\n",
    "#     central = pytz.timezone('US/Central')\n",
    "#     d = datetime.datetime.strptime(event.end_date_time, '%d-%b-%y %H:%M:%S')\n",
    "#     local = central.localize(d)\n",
    "#     utc = local.astimezone(pytz.utc)\n",
    "#     station = event.wfo\n",
    "#     station = UpdateStationCode(station)\n",
    "#     selectedTimes = getSelectedTimes(station,utc)\n",
    "#     tornadoTime = utc.strftime('%H:%M:%S')\n",
    "#     if (selectedTimes !=  []):\n",
    "#         closestTimeStamp, formatted = closestTime(tornadoTime,selectedTimes)\n",
    "#         key = buildKey(station,utc,closestTimeStamp)\n",
    "#         filename = buildFileID(station,utc,closestTimeStamp)\n",
    "#         if(not os.path.isfile(filename)):\n",
    "#             #GetFileFromNexradAWS(key)\n",
    "#             print closestTimeStamp\n",
    "#             print \"Volume Time: \",formatted\n",
    "#             VolumeTime.append(formatted)\n",
    "#             print \"Tornado Time: \",tornadoTime\n",
    "#             TornadoTime.append(tornadoTime)\n",
    "#             filenames.append(filename)\n",
    "#             if event.event_type == \"Tornado\":\n",
    "#                 IsTornado.append(1)\n",
    "#                 print \"Tornado : \", round(float(i)/len(weather) * 100,2)\n",
    "#             else:\n",
    "#                 IsTornado.append(0)\n",
    "#                 print \"Event   : \", round(float(i)/len(weather) * 100,2)\n",
    "            \n",
    "#     else:\n",
    "#         print \"Event   : \",i/len(weather)\n",
    "#         print \"Could not find keys for: \", station, tornadoTime\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print len(VolumeTime)\n",
    "print len(TornadoTime)\n",
    "print len(IsTornado)\n",
    "print len(episode_ids)\n",
    "print len(event_ids)\n",
    "#print len(BeginLat)\n",
    "#print len(BeginLong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tornadoClassification = pd.DataFrame({\"Filename\":filenames,\"IsTornado\":IsTornado,\"TornadoTime\":TornadoTime,\"VolumeTime\":VolumeTime,\"OriginalTime\":OriginalTime,\"BeginLat\":BeginLat,\"BeginLong\":BeginLong},columns = [\"Filename\",\"IsTornado\",\"TornadoTime\",\"VolumeTime\",\"OriginalTime\",\"BeginLat\",\"BeginLong\"])\n",
    "tornadoClassification = pd.DataFrame({\"Filename\":filenames,\"IsTornado\":IsTornado,\"TornadoTime\":TornadoTime,\"VolumeTime\":VolumeTime,\"OriginalTime\":OriginalTime,\"Episode_ID\":episode_ids,\"Event_ID\":event_ids},columns = [\"Filename\",\"IsTornado\",\"Episode_ID\",\"Event_ID\",\"TornadoTime\",\"VolumeTime\",\"OriginalTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tornadoClassification.IsTornado.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tornadoClassification.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>IsTornado</th>\n",
       "      <th>Episode_ID</th>\n",
       "      <th>Event_ID</th>\n",
       "      <th>TornadoTime</th>\n",
       "      <th>VolumeTime</th>\n",
       "      <th>OriginalTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>KHTX20150420_054230_V06.gz</td>\n",
       "      <td>1</td>\n",
       "      <td>93462</td>\n",
       "      <td>569838</td>\n",
       "      <td>05:45:00</td>\n",
       "      <td>05:42:30</td>\n",
       "      <td>00:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>KBMX20150419_123417_V06.gz</td>\n",
       "      <td>1</td>\n",
       "      <td>95580</td>\n",
       "      <td>574226</td>\n",
       "      <td>12:38:00</td>\n",
       "      <td>12:34:17</td>\n",
       "      <td>07:38:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>KHTX20150714_223427_V06.gz</td>\n",
       "      <td>1</td>\n",
       "      <td>96381</td>\n",
       "      <td>593977</td>\n",
       "      <td>22:35:00</td>\n",
       "      <td>22:34:27</td>\n",
       "      <td>17:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>KHTX20150714_221310_V06.gz</td>\n",
       "      <td>1</td>\n",
       "      <td>96381</td>\n",
       "      <td>593967</td>\n",
       "      <td>22:14:00</td>\n",
       "      <td>22:13:10</td>\n",
       "      <td>17:14:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>KHTX20150714_224515_V06.gz</td>\n",
       "      <td>1</td>\n",
       "      <td>96381</td>\n",
       "      <td>593971</td>\n",
       "      <td>22:48:00</td>\n",
       "      <td>22:45:15</td>\n",
       "      <td>17:48:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Filename  IsTornado  Episode_ID  Event_ID TornadoTime  \\\n",
       "19   KHTX20150420_054230_V06.gz          1       93462    569838    05:45:00   \n",
       "25   KBMX20150419_123417_V06.gz          1       95580    574226    12:38:00   \n",
       "82   KHTX20150714_223427_V06.gz          1       96381    593977    22:35:00   \n",
       "186  KHTX20150714_221310_V06.gz          1       96381    593967    22:14:00   \n",
       "195  KHTX20150714_224515_V06.gz          1       96381    593971    22:48:00   \n",
       "\n",
       "    VolumeTime OriginalTime  \n",
       "19    05:42:30     00:45:00  \n",
       "25    12:34:17     07:38:00  \n",
       "82    22:34:27     17:35:00  \n",
       "186   22:13:10     17:14:00  \n",
       "195   22:45:15     17:48:00  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tornadoClassification[tornadoClassification[\"IsTornado\"] == 1 ].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tornadoClassification.to_sql(\"weather\",con = engine, if_exists = \"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GetBucketSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
